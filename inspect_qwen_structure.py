#!/usr/bin/env python3
"""Inspect Qwen3-VL model structure to find vision encoder."""

import torch
from transformers import AutoModelForImageTextToText

print("=" * 80)
print("Qwen3-VL ëª¨ë¸ êµ¬ì¡° ê²€ì‚¬")
print("=" * 80)

# Load model (minimal loading to save memory)
print("\nëª¨ë¸ ë¡œë”© ì¤‘...")
model = AutoModelForImageTextToText.from_pretrained(
    "Qwen/Qwen3-VL-8B-Thinking",
    trust_remote_code=True,
    torch_dtype=torch.float16,
    device_map="auto",
)

print("\nâœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

# 1. Print model type
print(f"\nëª¨ë¸ íƒ€ì…: {type(model).__name__}")

# 2. Print top-level attributes
print("\n" + "=" * 80)
print("Top-level ì†ì„±ë“¤:")
print("=" * 80)
for name in dir(model):
    if not name.startswith('_'):
        attr = getattr(model, name, None)
        if isinstance(attr, torch.nn.Module):
            print(f"  âœ“ {name}: {type(attr).__name__}")

# 3. Check common vision encoder names
print("\n" + "=" * 80)
print("Vision ì¸ì½”ë” í›„ë³´ ê²€ì‚¬:")
print("=" * 80)

candidates = [
    'visual',
    'vision_model',
    'vision_tower',
    'vision_encoder',
    'img_encoder',
    'image_encoder',
    'transformer',
    'model',
]

found_vision = None
for candidate in candidates:
    if hasattr(model, candidate):
        attr = getattr(model, candidate)
        print(f"  âœ“ '{candidate}' ë°œê²¬: {type(attr).__name__}")
        if found_vision is None and isinstance(attr, torch.nn.Module):
            found_vision = candidate
    else:
        print(f"  âœ— '{candidate}' ì—†ìŒ")

# 4. If model has 'model' or 'transformer', check its attributes
print("\n" + "=" * 80)
print("ì¤‘ì²©ëœ êµ¬ì¡° ê²€ì‚¬:")
print("=" * 80)

for parent_name in ['model', 'transformer']:
    if hasattr(model, parent_name):
        parent = getattr(model, parent_name)
        print(f"\n'{parent_name}' ì˜ í•˜ìœ„ ì†ì„±ë“¤:")
        for name in dir(parent):
            if not name.startswith('_'):
                attr = getattr(parent, name, None)
                if isinstance(attr, torch.nn.Module):
                    print(f"    âœ“ {parent_name}.{name}: {type(attr).__name__}")
                    # Check if this might be vision encoder
                    if 'vis' in name.lower() or 'image' in name.lower() or 'img' in name.lower():
                        print(f"      ğŸ‘ï¸  ë¹„ì „ ê´€ë ¨ ëª¨ë“ˆ ê°€ëŠ¥ì„± ë†’ìŒ!")
                        if found_vision is None:
                            found_vision = f"{parent_name}.{name}"

# 5. Print model structure
print("\n" + "=" * 80)
print("ì „ì²´ ëª¨ë¸ êµ¬ì¡° (ê°„ëµ):")
print("=" * 80)
print(model)

# 6. Recommendation
print("\n" + "=" * 80)
print("ê¶Œì¥ ì‚¬í•­:")
print("=" * 80)
if found_vision:
    print(f"âœ… Vision ì¸ì½”ë”ë¡œ '{found_vision}' ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    print(f"\nìˆ˜ì •í•  ì½”ë“œ:")
    print(f"  self.vision_model = model.{found_vision}")
else:
    print("âš ï¸  Vision ì¸ì½”ë”ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print("ìœ„ì˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.")

print("=" * 80)
